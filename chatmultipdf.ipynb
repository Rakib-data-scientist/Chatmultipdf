{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-pKffb-uUlc"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install unstructured\n",
        "!pip install sentence_transformers\n",
        "!pip install pinecone-client\n",
        "!pip install llama-cpp-python\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader, OnlinePDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import pinecone\n",
        "import os"
      ],
      "metadata": {
        "id": "syt7CmH6uZcd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/2308.12261v1.pdf\")"
      ],
      "metadata": {
        "id": "HYTjoHMjua13"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/2308.13418v1.pdf\")"
      ],
      "metadata": {
        "id": "6BTwUo-c90HF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "pDaeu_8_ua4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "\n",
        "\n",
        "docs=text_splitter.split_documents(data)\n",
        "\n",
        "\n",
        "len(docs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgbZ4KZPulR6",
        "outputId": "e8ecbb37-5cc3-4405-988e-c4439f51ed6e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB7f-1W5ulUp",
        "outputId": "c7fcaf6a-5918-43c2-b7aa-a80e742ea252"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='PROMPT 2MODEL :\\nGenerating Deployable Models from Natural Language Instructions\\nVijay Viswanathan1∗, Chenyang Zhao1,2∗,\\nAmanda Bertsch1, Tongshuang Wu1, Graham Neubig1\\n1Carnegie Mellon University,2Tsinghua University\\nAbstract\\nLarge language models (LLMs) enable system\\nbuilders today to create competent NLP sys-\\ntems through prompting, where they only need\\nto describe the task in natural language and\\nprovide a few examples. However, in other\\nways, LLMs are a step backward from tradi-', metadata={'source': '/content/2308.12261v1.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_eLonpUwvGKPtZGTywgjBx\"\n",
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'd2d6c3d-9d50-37a8a0697ed3')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')"
      ],
      "metadata": {
        "id": "wVST2rQ7ulaY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "3KUCN4OMuldH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_API_ENV\n",
        ")\n",
        "index_name = \"multipdfchat\""
      ],
      "metadata": {
        "id": "fjA8kZmdulf0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch=Pinecone.from_texts([t.page_content for t in docs], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "ZTgD5f59ulin"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what is Nougat\"\n",
        "\n",
        "\n",
        "docs=docsearch.similarity_search(query)\n",
        "\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoWLMMbXullh",
        "outputId": "c31e0592-3979-474b-e8ed-d8930c4c74f3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='3https://github.com/facebookresearch/nougatarXiv:2308.13418v1  [cs.LG]  25 Aug 2023', metadata={}),\n",
              " Document(page_content='Explore the examples in this section on the project page: https://facebookresearch.github.io/nougat.\\n11https://archive.org/\\n12https://www.gutenberg.org/\\n13', metadata={}),\n",
              " Document(page_content='Nougat base (350M∗)All 0.071 89.1 93.0 93.5 92.8 93.1\\nTables 0.211 69.7 79.1 75.4 80.7 78.0\\nPlain text 0.058 91.2 94.6 96.2 95.3 95.7\\nMath 0.128 56.9 75.4 76.5 76.6 76.5\\nTable 1: Results on arXiv test set. PDF is the text embedded in the PDF file. The modality “All” refers to the output\\ntext without any splitting.∗Number of parameters.\\n5.2 Text modalities\\nIn a scientific research article, there are three distinct types of text: 1) plain text, which comprises the majority of the', metadata={}),\n",
              " Document(page_content='Nougat Blecher et al.\\nMethod Modality Edit distance ↓BLEU ↑METEOR ↑Precision ↑Recall ↑F1↑\\nPDF All 0.255 65.8 82.1 77.1 81.4 79.2\\nGROBID All 0.312 55.6 71.9 74.0 72.1 73.0\\nTables 0.626 25.1 64.5 61.4 80.7 69.7\\n+ LaTeX OCR Plain text 0.363 57.4 69.2 82.1 70.5 75.9\\nMath 0.727 0.3 5.0 11.0 8.6 9.7\\nNougat small (250M∗)All 0.073 88.9 92.8 93.6 92.2 92.9\\nTables 0.220 68.5 78.6 75.0 79.8 77.3\\nPlain text 0.058 91.0 94.3 96.1 95.3 95.7\\nMath 0.117 56.0 74.7 77.1 76.8 76.9', metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "\n",
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.1, \"max_length\":512})\n",
        "\n",
        "\n",
        "chain=load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "\n",
        "query=\"Prompting LLMs can be expensive as\"\n",
        "docs=docsearch.similarity_search(query)\n",
        "\n",
        "\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GIz0y0ndzRtM",
        "outputId": "60cb01d8-1b78-499d-8403-26a884fac59e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'they require either a significant amount of com- puting or access to commercial APIs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}